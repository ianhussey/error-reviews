---
title: "Fetching Paper and Journal metadata from Scopus"
author: "Ian Hussey & Jamie Cummins"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, include = TRUE, warning = FALSE, message = FALSE)
```

# Source

Code adapted from [Julian Quandt's repo](https://github.com/julianquandt/zcurve_autorep).

# Dependencies

```{r}

library(dplyr)
library(tidyr)
library(readr)
library(rcrossref)
library(purrr)
library(janitor)
library(lubridate)
library(knitr)
library(kableExtra)

```

# Load journal ISSNs to be searched

```{r}

issn_dat <- read_csv("../data/journals/processed_journal_issns.csv") 

issn_vector <- issn_dat |>
  pull(issn)

```

# Functions for query

```{r}

# Author names are stored within a tibble for each entry.
# Therefore, author names must be extracted using this function.
concatenate_authors <- function(authors_tibble) {
  # Combine 'given' and 'family' to get full names for each author in the tibble
  if(is.null(authors_tibble)) return(character(0))
  
  full_names <- apply(authors_tibble, 1, function(row) {
    paste(row['given'], row['family'])
  })
  
  # Concatenate all names into a single string
  return(paste(full_names, collapse = ", "))
}

# this is a small convenience function to retrieve the publication year from a publication entry that is formatted (yyyy-mm-dd)
retrieve_pubyear <- function(publication) {
  # Extract details from the publication tibble
  year <- ifelse(!is.null(publication$`published.print`), substr(publication$`published.print`, 1, 4), "")
  return(year)
}

# we want to generate APA-style citations for each publication
# to achieve this, we need to extract the relevant information for each publication and format it accordingly
generate_apa_citation <- function(publication) {
  # Extract details from the publication tibble
  title <- ifelse(length(publication$title) > 0, publication$title[[1]], "")
  authors <- ifelse(!is.null(publication$author), concatenate_authors(publication$author), character(0))
  doi <- ifelse(!is.null(publication$doi), publication$doi, "")
  link <- ifelse(!is.null(publication$url), publication$url, "")
  issue <- ifelse(!is.null(publication$issue), publication$issue, "")
  year <- ifelse(!is.null(publication$`published.print`), retrieve_pubyear(publication), "")
  journal <- ifelse(length(publication$`container.title`) > 0, publication$`container.title`, "")
  volume <- ifelse(!is.null(publication$volume), gsub("\\(.*\\)", "", publication$volume), "")
  pages <- ifelse(!is.null(publication$page), publication$page, "")
  
  # format authors in APA style (last name, initials)
  formattedAuthors <- sapply(unlist(strsplit(authors, ", ")), function(author) {
    nameParts <- unlist(strsplit(author, " "))
    lastName <- tail(nameParts, 1) # Last name
    # For initials, consider all name parts except the last one (family name)
    initials <- paste0(substr(nameParts[-length(nameParts)], 1, 1), collapse = ".")
    return(paste(lastName, paste0(initials, "."), sep = ", "))
  })
  
  # Collapse the resulting vector to a single string
  formattedAuthors <- paste(formattedAuthors, collapse = ", ")
  
  # Create the APA reference
  apaReference <- sprintf("%s (%s). %s. %s, %s(%s), %s. %s", formattedAuthors, year, title, journal, volume, issue, pages, doi)
  return(apaReference)
}

fetch_publications <- function(journalISSN, startYear, endYear, cursor = "*", clean_unpublished = FALSE) {
  
  # Make the request
  res <- tryCatch({
    cr_journals(
      issn = journalISSN,
      filter = c(from_pub_date = startYear, until_pub_date = endYear), works = TRUE,
      # works = TRUE means that we want to fetch the publications of the journal
      cursor = cursor, 
      # cursor = "*" means that we want to fetch the first batch of publications
      .progress = TRUE
      # .progress = TRUE means that we want to see a progress bar
    )
    #catch case where there is only 1 page and hence progress bar would throw error
  }, error = function(e) {
    if (grepl("must have 'max' > 'min'", e$message)) {
      message("Error with progress bar. This means there is probably only 1 page of results... retrying without progress bar...")
      cr_journals(
        issn = journalISSN,
        filter = c(from_pub_date = startYear, until_pub_date = endYear), works = TRUE,
        cursor = cursor, 
        .progress = FALSE
      )
    } else {
      stop(e)
    }
  })
  
  # after finishing the initial fetching, we want to format the authors as a single string (they are stored in data-sets within each publication entry by default)
  author_strings <- lapply(res$data$author, concatenate_authors)
  
  # we also want to generate APA-style citations for each publication
  apa_citations <- apply(res$data, 1, function(row) {
    return(generate_apa_citation(row))
  })
  
  # and we want to retrieve the publication year from the publication entry
  years <- apply(res$data, 1, function(row) {
    return(retrieve_pubyear(row))
  })
  
  # append the columns to the data frame
  res$data$authors <- rep(NA)
  res$data$authors <- author_strings
  res$data$apa_citation <- rep(NA)
  res$data$apa_citation <- apa_citations
  res$data$year <- rep(NA)
  res$data$year <- years
  
  # for information purposes, print the number of publications that were fetched
  
  if(clean_unpublished) {
    nrow_before <- nrow(res$data)
    print("cleaned")
    # remove all publications that are not published yet
    res$data <- res$data[!is.na(res$data$year), ]
    print(nrow(res$data[!is.na(res$data$year), ]))
    print(nrow(res$data))
    message(paste("Fetched", nrow(res$data), "publications.", nrow_before - nrow(res$data), "were deleted due to not being published yet."))
  } else {
    message(paste("Fetched", nrow(res$data), "publications."))
  }
  
  # return all publications
  return(res$data)
}

# Function to extract the URL for the 'text/html' content type
extract_html_url <- function(nested_df) {
  url <- nested_df %>%
    filter(content.type == "text/html") %>%
    pull(URL)
  
  # Return first match or NA if none found
  if (length(url) == 0) NA_character_ else url[1]
}

```

# Run the query

(estimated at 1hour 20mins for 1 year)

```{r}

data_publications_temp <- 
  expand_grid(issn = issn_vector, 
              pubyear_start = 2015, 
              pubyear_end = 2025) |>
  mutate(res = pmap(list(issn,
                         pubyear_start,
                         pubyear_end),
                    possibly(fetch_publications, otherwise = NA))) 

data_publications <- data_publications_temp |>
  rename(issn_orig = issn) |>
  unnest(res) |>
  distinct(doi, .keep_all = TRUE) |>
  mutate(year = lubridate::year(lubridate::ymd(deposited))) |>
  select(issn, 
         doi,
         authors, 
         year,
         title, 
         journal = container.title,
         volume,
         issue, 
         pages = page,
         apa_reference = apa_citation,
         link, # nested daf needs wrangling
         citation_count = is.referenced.by.count,
         pubyear_search_start = pubyear_start,
         pubyear_search_end = pubyear_end) |>
  # wrangle citations per year
  mutate(year_for_citations_by_year = ifelse(year > pubyear_search_end-1, pubyear_search_end, year)) |>
  mutate(citation_count = as.numeric(as.character(citation_count)),
         citations_per_year = round_half_up(citation_count / (pubyear_search_end-1 - year_for_citations_by_year), 2),
         more_than_30_citations_per_year = citations_per_year >= 30) |>
  # extract link from nested df link column
  mutate(link = map_chr(link, extract_html_url))

# write to disk
# write_csv(data_publications, "../data/articles/data_publications_crossref.csv")

```

# Session info

```{r}

sessionInfo()

```

