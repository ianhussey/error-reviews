---
title: "Fetching Paper and Journal metadata from Scopus"
author: "Ian Hussey & Julian Quandt"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: cerulean
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float: true
    self_contained: true
    code_folding: hide
    code_download: true
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, include = TRUE, warning = FALSE, message = FALSE)
```

# Source

Code adapted from [Julian Quandt's repo](https://github.com/julianquandt/zcurve_autorep).

# About

This file demonstrates how to use the Scopus Api to collect all papers from a journal or list of journals. 
Moreover, it shows how to collect the metadata of the journals themselves.

<div style="border: 1px solid #999; border-radius: 5px; padding: 20px; margin-top: 20px; background-color: #ffffe0;">
  <h3 style="color: #0056b3; margin-top: 0;">The code in this document</h3>
  In this HTML version of the document, the code chunks that are just doing background work or intermediate steps are hidden to make it more readable. If you want to see the code, you can click on the "Show" buttons on the right hand side of the text. To run the code in R yourself, download the .Rmd file by clicking on the "Code" button on the top right of the document and then selecting "Download Rmd".
</div>

# Minimal example

Remember to connect to UniBe VPN (via FortiClient) before running

```{r}

library(dplyr)
library(tidyr)
library(rscopus)
library(jsonlite)
library(stringr)
library(httr)


pubyear_start <- 2015
pubyear_end <- 2025

# Set your Scopus API key
source("../../secret_vars.R")
set_api_key(scopus_key)

query_return <-
  rscopus::scopus_search(query = paste0("ISSN(", issn, ") AND PUBYEAR > ", (pubyear_start-1), " AND PUBYEAR < ", (pubyear_end+1)),
                         view = "STANDARD",
                         max_count = 10000,
                         count = 200,
                         verbose = FALSE,
                         wait_time = 1)

# convert the queried items to a data frame by calling the queried_items_to_df function from above
queried_items_df <- queried_items_to_df(query_return[[1]])
# process the queried items by calling the process_queried_items_df function from above
processed_item_df <- process_queried_items_df(queried_items_df)
# # merge the processed items with the previously processed items
# if(is.null(processed_df_final)){
#   processed_df_final <- processed_item_df
# } else {
#   processed_df_final <- rbind.fill(processed_df_final, processed_item_df)
# }

dat <- processed_item_df |>
  mutate(citation_count = as.numeric(as.character(citation_count)),
         year = as.numeric(as.character(year)),
         year = ifelse(year > 2023, 2023, year)) |>
  mutate(citations_per_year = round_half_up(citation_count / (2024 - year), 0),
         required_citations_per_year = citations_per_year >= 30) |>
  arrange(desc(citations_per_year))

dat |>
  count(required_citations_per_year) |>
  pivot_wider(names_from = "required_citations_per_year",
              values_from = "n",
              names_prefix = "required_citations_per_year_") |>
  rename(n_meeting_threshold = required_citations_per_year_TRUE,
         n_not_meeting_threshold = required_citations_per_year_FALSE) |>
  mutate(percent_meeting_threshold = round_half_up(n_meeting_threshold/(n_meeting_threshold + n_not_meeting_threshold)*100, 1))

```

